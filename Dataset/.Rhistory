# Return the predicted labels
return(predictions)
predict_RGEC_classifier <- function(model, projected_test_data) {
# Make predictions on the projected data
predictions <- predict(model, newdata = as.data.frame(projected_test_data))
# Return the predicted labels
return(predictions)
}
# ReGEC Classifier Updated
# Load the required packages
# install.packages("e1071", dep = TRUE)
library(MASS)
library(caret)
library(e1071)
# Load the Cleveland Heart Disease dataset
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data"
data <- read.csv(url, header = FALSE, na.strings = "?")
# Checking how many rows is the dataset = 303
nrow(data)
# Assign column names to the dataset
colnames(data) <- c("age", "sex", "cp", "trestbps", "chol", "fbs", "restecg",
"thalach", "exang", "oldpeak", "slope", "ca", "thal", "target")
# There are some rows of data that contain Na, based on the observation
# we can drop them from the dataset
data <- data[!(is.na(data$ca) | is.na(data$thal)),]
nrow(data) #303 - 6 = 297 rows remaining
# Convert the target variable to a factor
data$target <- factor(ifelse(data$target == 0, "negative", "positive"))
# Feature Extraction using LDA approach
feature_extraction <- function(target, train_data, test_data) {
# Fit an LDA model to the training data
lda.fit <- lda(target ~ ., data= train_data)
# Extract the LDA features from the training and testing data
train_lda <- predict(lda.fit, train_data)
test_lda <- predict(lda.fit, test_data)
return(c(train_lda=train_lda, test_lda=test_lda))
}
predict_RGEC_classifier <- function(model, projected_test_data) {
# Make predictions on the projected data
predictions <- predict(model, newdata = as.data.frame(projected_test_data))
# Return the predicted labels
return(predictions)
}
train_RGEC_classifier <- function(data) {
# Train/test splitting the dataset to 90/10
set.seed(123)
train_index <- createDataPartition(data$target, p = 0.9, list = FALSE)
train_data <- data[train_index,]
test_data <- data[-train_index,]
colnames(train_data)
colnames(test_data)
# LDA Feature Extraction
lda <- feature_extraction(target=train_data$target, train_data, test_data)
lda_train_features = lda$train_lda.x
lda_test_features = lda$test_lda.x
# Defining the regularization parameter to help prevent over-fitting.
regularization_parameter <- 0.1
# Compute the overall mean and variance for train features
train_mean <- colMeans(lda_train_features)
train_conv <- cov(lda_train_features)
# Compute the between-class and within-class scatter matrices
train_within_class <- train_conv +
diag(regularization_parameter, ncol(lda_train_features))
train_between_class <- (t(train_mean - lda_train_features)
%*% (train_mean - lda_train_features)) / nrow(lda_train_features)
# Compute the generalized eigenvectors and eigenvalues
eigen <- eigen(solve(train_within_class) %*% train_between_class)
# Sort the eigenvalues in descending order
eigen_order <- order(eigen$values, decreasing = TRUE)
eigen$values <- eigen$values[eigen_order]
eigen$vectors <- eigen$vectors[, eigen_order]
# Obtain the projection matrix - matrix d
projection_matrix <- as.matrix(eigen$vectors)
# Project the test data on the selected eigenvectors, to transform the sample
# onto the new subspace - d * k eigenvector matrix
projected_train_data <- as.matrix(lda_train_features) %*% projection_matrix
projected_test_data <- as.matrix(lda_test_features) %*% projection_matrix
dim(projected_train_data)
colnames(train_data)
# Train SVM model on the projected training data using both kernels
# (linear and gaussian)
svm_model <- svm(x = projected_train_data, y = train_data$target, kernel="linear", cost=1)
# Obtain the predictions
predictions <- predict_RGEC_classifier(svm_model, projected_test_data)
confusionMatrix(table(predictions, test_data$target))
return(predictions)
}
predictions = train_RGEC_classifier(data)
predictions
library(MASS)
library(caret)
library(e1071)
# Load the Cleveland Heart Disease dataset
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data"
data <- read.csv(url, header = FALSE, na.strings = "?")
# Checking how many rows is the dataset = 303
nrow(data)
# Assign column names to the dataset
colnames(data) <- c("age", "sex", "cp", "trestbps", "chol", "fbs", "restecg",
"thalach", "exang", "oldpeak", "slope", "ca", "thal", "target")
# There are some rows of data that contain Na, based on the observation
# we can drop them from the dataset
data <- data[!(is.na(data$ca) | is.na(data$thal)),]
nrow(data) #303 - 6 = 297 rows remaining
# Convert the target variable to a factor
data$target <- factor(ifelse(data$target == 0, "negative", "positive"))
# Feature Extraction using LDA approach
feature_extraction <- function(target, train_data, test_data) {
# Fit an LDA model to the training data
lda.fit <- lda(target ~ ., data= train_data)
# Extract the LDA features from the training and testing data
train_lda <- predict(lda.fit, train_data)
test_lda <- predict(lda.fit, test_data)
return(c(train_lda=train_lda, test_lda=test_lda))
}
predict_RGEC_classifier <- function(model, projected_test_data) {
# Make predictions on the projected data
predictions <- predict(model, newdata = as.data.frame(projected_test_data))
# Return the predicted labels
return(predictions)
}
train_RGEC_classifier <- function(data) {
# Train/test splitting the dataset to 90/10
set.seed(123)
train_index <- createDataPartition(data$target, p = 0.9, list = FALSE)
train_data <- data[train_index,]
test_data <- data[-train_index,]
colnames(train_data)
colnames(test_data)
# LDA Feature Extraction
lda <- feature_extraction(target=train_data$target, train_data, test_data)
lda_train_features = lda$train_lda.x
lda_test_features = lda$test_lda.x
# Defining the regularization parameter to help prevent over-fitting.
regularization_parameter <- 0.1
# Compute the overall mean and variance for train features
train_mean <- colMeans(lda_train_features)
train_conv <- cov(lda_train_features)
# Compute the between-class and within-class scatter matrices
train_within_class <- train_conv +
diag(regularization_parameter, ncol(lda_train_features))
train_between_class <- (t(train_mean - lda_train_features)
%*% (train_mean - lda_train_features)) / nrow(lda_train_features)
# Compute the generalized eigenvectors and eigenvalues
eigen <- eigen(solve(train_within_class) %*% train_between_class)
# Sort the eigenvalues in descending order
eigen_order <- order(eigen$values, decreasing = TRUE)
eigen$values <- eigen$values[eigen_order]
eigen$vectors <- eigen$vectors[, eigen_order]
# Obtain the projection matrix - matrix d
projection_matrix <- as.matrix(eigen$vectors)
# Project the test data on the selected eigenvectors, to transform the sample
# onto the new subspace - d * k eigenvector matrix
projected_train_data <- as.matrix(lda_train_features) %*% projection_matrix
projected_test_data <- as.matrix(lda_test_features) %*% projection_matrix
dim(projected_train_data)
colnames(train_data)
# Train SVM model on the projected training data using both kernels
# (linear and gaussian)
svm_model <- svm(x = projected_train_data, y = train_data$target, kernel="linear", cost=1)
# Obtain the predictions
predictions <- predict_RGEC_classifier(svm_model, projected_test_data)
confusionMatrix(table(predictions, test_data$target))
return(predictions)
}
predictions = train_RGEC_classifier(data)
predictions
kernel <- function(A,B){
nRow_A = nrow(A)
nRow_B = nrow(B)
}
kernel <- function(A,B,sigma){
nRow_A <- nrow(A)
nRow_B <- nrow(B)
k <- marix(0, nrow= nRow_A, ncol=nRow_B)
for (i in 1:nRow_A){
for (j in 1:nRow_B){
x <- -norm(A[i,]-B[j])^2
k[i,j] <- exp(x/sigma)
}
}
}
list.files()
list.files()
# Import all the necessary libraries
library(tidyverse)
library(tidymodels)
library(caret)
library(ggplot2)
library(corrplot)
library(FNN)
#*_____________________________________________Data Loading__________________________________________________*#
# Set the working directory where all the files are located
setwd("D:\\Erasmus Mundus Masters\\University of Cassino\\Statistical Learning and Data Mining\\Project\\Regression Challenge\\Dataset")
# Import the train and test dataset from the directory as data frame
train_data <- read.csv("train_ch.csv")
test_data <- read.csv("test_ch.csv")
# Extract index column of the test data
test_index <- test_data[, 1]
# Removing the index column from the train and test data set
train_data <- train_data[, -1]
test_data <- test_data[, -1]
# Extract the input variables and result from the train data set
train_data_input_variables <- train_data[, -ncol(train_data)]
train_data_result <- train_data$Y
# Visualize all input variables of the train data
par(mfrow = c(3, 3))                                   # Adjust the number of rows and columns as per input variables
colors <- c("black", "green", "blue", "red", "orange",
"purple", "cyan", "magenta", "brown")      # Specify colors for each input variable
for (i in 1:9) {
plot(train_data_input_variables[, i], train_data_result,
col = colors[i], pch = 16,
xlab = paste("Input Variable V",i), ylab = "Result Y")
}
# Visualize outliers in train input variables using boxplot
boxplot(train_data_input_variables)
# Find outliers for each input variable
outliers <- sapply(train_data_input_variables, function(x) {
boxplot.stats(x)$out
})
# Identify input variables with outliers
variables_with_outliers <- names(outliers)[sapply(outliers, length) > 0]
# Count the number of outliers for each input variable
outlier_counts <- sapply(outliers, length)
# Print the input variables with outliers
cat("Input variables with outliers:", paste(variables_with_outliers, collapse = ", "), "\n")
# Find and print the total number of outliers
total_outliers <- sum(outlier_counts)
cat("Total number of outliers:", total_outliers, "\n")
# Perform mean imputation for input variables with outliers
for (variable in variables_with_outliers) {
outlier_indices <- which(train_data_input_variables[, variable] %in% outliers[[variable]])
train_data_input_variables[outlier_indices, variable] <- mean(train_data_input_variables[, variable], na.rm = TRUE)
}
# Verify the imputation by checking for outliers again
outliers_after_imputation <- sapply(train_data_input_variables, function(x) {
boxplot.stats(x)$out
})
# Identify input variables with outliers after imputation
variables_with_outliers_after_imputation <- names(outliers_after_imputation)[sapply(outliers_after_imputation, length) > 0]
# Count the number of outliers after imputation for each input variable
outlier_counts_after_imputation <- sapply(outliers_after_imputation, length)
# Print the number of outliers after imputation for each input variable
cat("Number of outliers after imputation for each input variable:\n")
print(outlier_counts_after_imputation)
# Visualize train data input variables after outliers inputation using boxplot
boxplot(train_data_input_variables)
# New train data after outliers imputation (no outliers in the train data)
train_data <- cbind(train_data_input_variables,train_data_result)
colnames(train_data)[ncol(train_data)] <- "Y"
# Function for computing correlation matrix of train predictors
get_correlation_matrix <- function (x){
# input: x = train predictors
# output: x = train predictors with (<0.75 CF)
corre_matrix <- cor(x, method = "pearson")         # get the correlation matrix
corrplot(corre_matrix, method = "color")           # Plot the correlation matrix
index <- findCorrelation(corre_matrix, .75)        # select predictors who have more than 75% CF
remove_predictors <- colnames(corre_matrix)[index] # remove predictors having more than 75% CF from the correlation matrix
x <- x[!names(x) %in% remove_predictors]           # remove predictors with high CF from the train predictors
return(x)
}
# Compute correlation matrix and remove correlated features from the dataset
corre_reduced_train_data <- get_correlation_matrix(train_data)
# Checke dimensions of datasets
dim(train_data_input_variables)
dim(corre_reduced_train_data)
# New train data after removing highly correlated input variables
reduced_train_data <-  cbind(corre_reduced_train_data, train_data_result)
colnames(reduced_train_data)[ncol(reduced_train_data)] <- "Y"
# Get summary of original train data and reduced train data (after removing highly correlated input variables)
summary(train_data)
summary(reduced_train_data)
# Train the linear regression model with input variables and eliminate variables based on p-value
model1 = lm(Y~v1+v2+v3+v4+v6+v8+v9, data=reduced_train_data) # all input variables are used except v5, v7 because highly correlated
summary(model1)
model2 = lm(Y~v1+v3+v4+v6+v8+v9, data=reduced_train_data)    # variable v2 is eliminated based on p-value
summary(model2)
model3 = lm(Y~v1+v3+v4+v6+v8, data=reduced_train_data)       # variable v9 is eliminated based on p-value
summary(model3)
model4 = lm(Y~v1+v3+v6+v8, data=reduced_train_data)          # variable v4 is eliminated based on p-value
summary(model4)
model5 = lm(Y~v1+v3+v6, data=reduced_train_data)             # variable v8 is eliminated based on p-value
summary(model5)
model6 = lm(Y~v1+v3, data=reduced_train_data)                # variable v6 is eliminated based on p-value
summary(model6)
model7 = lm(Y~v3, data=reduced_train_data)                   # variable v3 is eliminated based on p-value
summary(model7)
# Train model with the input variables and interactive terms of v1 and v3
model8 = lm(Y~v3+I(v1*v3), data=reduced_train_data)
summary(model8)
model19 = lm(Y~v1+v3+I(v1*v3), data=reduced_train_data)                    # variable v1 is added based on p-value
summary(model19)
model10 = lm(Y~v1+v3+v6+I(v1*v3), data=reduced_train_data)                 # variable v6 is added based on p-value
summary(model10)
model11 = lm(Y~v1+v3+v6+v8+I(v1*v3), data=reduced_train_data)              # variable v8 is added based on p-value
summary(model11)
model12 = lm(Y~v1+v3+v4+v6+v8+I(v1*v3), data=reduced_train_data)           # variable v4 is added based on p-value
summary(model12)
model13 = lm(Y~v1+v3+v4+v6+v8+v9+I(v1*v3), data=reduced_train_data)        # variable v9 is added based on p-value
summary(model13)
model14 = lm(Y~v1+v2+v3+v4+v6+v8+v9+I(v1*v3), data=reduced_train_data)     # variable v2 is added based on p-value
summary(model14)
# Train model with the input variables and polynomial terms of v3
model15 = lm(Y~v3+I(v3*v3), data=reduced_train_data)
summary(model15)
model16 = lm(Y~v1+v3+I(v3*v3), data=reduced_train_data)
summary(model16)
model17 = lm(Y~v1+v3+v6+I(v3*v3), data=reduced_train_data)
summary(model17)
model18 = lm(Y~v1+v3+v6+v8+I(v3*v3), data=reduced_train_data)
summary(model18)
model19 = lm(Y~v1+v3+v4+v6+v8+I(v3*v3), data=reduced_train_data)
summary(model19)
model20 = lm(Y~v1+v3+v4+v6+v8+v9+I(v3*v3), data=reduced_train_data)
summary(model20)
model21 = lm(Y~v1+v2+v3+v4+v6+v8+v9+I(v3*v3), data=reduced_train_data)
summary(model21)
# Select the based model based on the minimum Residual Standard Error (RSE) and maximum R-Squared value
best_model = model21
# Predict the train data using the best model (Model 21)
train_prediction_result <- predict(best_model, newdata = train_data)
# Predict the test data using the best model (Model 21)
test_prediction_result <- predict(best_model, newdata = test_data)
# Compute error between train original result and train prediction result
train_mean_absolute_error <- mean(abs(train_data_result - train_prediction_result))
train_root_mean_squared_error <- sqrt(mean((train_data_result - train_prediction_result)^2))
train_r_squared <- 1 - sum((train_data_result - train_prediction_result)^2) / sum((train_data_result - mean(train_data_result))^2)
# Print the regression error metrics for train data
cat("Train MAE:", train_mean_absolute_error, "\n")
cat("Train RMSE:", train_root_mean_squared_error, "\n")
cat("Train R-squared:", train_r_squared, "\n")
# Function for normalization of the train data
min_max_norm <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
# Normalize the reduced train data (after removing the highly correlated input variables)
normalized_train_data <- as.data.frame(lapply(reduced_train_data, min_max_norm))
normalized_train_data <-  normalized_train_data[, c("v1","v3","Y")]
set.seed(123)  # for reproducibility
train_index <- sample(1:nrow(normalized_train_data), 0.8 * nrow(normalized_train_data))  # 80% for training
normalized_train_data_x <- normalized_train_data[train_index, ]  # train data; 80 percent of normalized_train_data
normalized_test_data_x <- normalized_train_data[-train_index, ]  # test data: 20 percent of normalized_train_data
# Separate input variables and result for training data
train_data_x <- normalized_train_data_x[, -ncol(normalized_train_data_x)]
train_data_y <- normalized_train_data_x[, ncol(normalized_train_data_x)]
# Function to calculate RMSE
calculate_rmse <- function(actual, predicted) {
sqrt(mean((actual - predicted)^2))
}
# Initialize variables
best_rmse <- Inf
optimal_k <- 0
rmse_values <- vector(length = 100)  # Vector to store RMSE values
# Perform iteration process to find optimal k and collect RMSE values
for (k in 1:100) {
knn_model <- knn.reg(train = train_data_x,                                           # train data input variable
test = normalized_test_data_x[, -ncol(normalized_test_data_x)], # test data input variable
y = train_data_y,      # train data  result
k = k)
predicted_values <- knn_model$pred
rmse <- calculate_rmse(normalized_test_data_x[, ncol(normalized_test_data_x)], predicted_values)
rmse_values[k] <- rmse
if (rmse < best_rmse) {
best_rmse <- rmse
optimal_k <- k
}
}
# Plot k versus RMSE
plot(1:100, rmse_values, type = "l", xlab = "k", ylab = "RMSE", main = "k vs RMSE")
points(optimal_k, best_rmse, col = "red", pch = 16)
legend("topright", legend = c("Optimal k"), col = "red", pch = 16)
# Print optimal k and RMSE
cat("Optimal k:", optimal_k, "\n")
cat("Minimum RMSE:", best_rmse, "\n")
# Train the best model using the optimal k
best_knn_model <- knn.reg(train = train_data_x,                                           # train data: input variable
test = normalized_test_data_x[, -ncol(normalized_test_data_x)], # test data: input variable
y = train_data_y,                                               # train data: result
k = optimal_k)
# Predict the entire train dataset using the best model
train_predictions <- knn.reg(train = train_data_x,      # train data: input variable
test = train_data_x,       # test data: input variable
y = train_data_y,          # train data: result
k = optimal_k)$pred
# Calculate MAE
mae <- mean(abs(train_data_y - train_predictions))
# Calculate RMSE
rmse <- calculate_rmse(train_data_y, train_predictions)
# Calculate R-squared
r_squared <- cor(train_data_y, train_predictions)^2
# Print the errors
cat("MAE:", mae, "\n")
cat("RMSE:", rmse, "\n")
cat("R-squared:", r_squared, "\n")
# Predict the entire test dataset using the best model
knn_test_predictions <- knn.reg(train = train_data_input_variables,  # train data: input variable
test = test_data,                        # test data: input variable
y = train_data$Y,                        # train data: result
k = optimal_k)$pred
# Make final result data
final_result_data <- cbind(test_index,knn_test_predictions)
colnames(final_result_data)[ncol(final_result_data)] <- "pred_knn"
final_result_data <- cbind(final_result_data,test_prediction_result)
colnames(final_result_data)[ncol(final_result_data)] <- "pred_ln"
colnames(final_result_data)[1] <- "index"
